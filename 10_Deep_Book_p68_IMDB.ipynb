{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10_Deep_Book_p68_IMDB.ipynb","provenance":[],"private_outputs":true,"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AfRwG-H_hI6r","colab_type":"code","colab":{}},"source":["from keras.datasets import imdb\n","from keras import models, layers, regularizers\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n","\n","print(\"Train len: {}, data 0: {}\".format(len(train_data), train_data[0]))\n","print(\"Test len: {}, data 0: {}\".format(len(test_data), test_data[0]))\n","print(train_labels[0])\n","\n","\n","# decode review back to words:\n","def decode_review(rev_index):\n","    word_index = imdb.get_word_index()\n","    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])  # key is word, value is number\n","    decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[rev_index]])\n","    print(decoded_review)\n","\n","\n","def vectorize_sequences(sequenses, dimension=10000):\n","    results = np.zeros((len(sequenses), dimension))\n","    print(\"Data results shape:\")\n","    print(results.shape)\n","    for i, sequense in enumerate(sequenses):\n","        #print(\"i: {}, sequense: {}\".format(i, sequense))\n","        #print(\"len sequense: {}\".format(len(sequense)))\n","        results[i, sequense] = 1\n","        #if i > 2:\n","            #break\n","    return results\n","\n","\n","x_train = vectorize_sequences(train_data)\n","x_test = vectorize_sequences(test_data)\n","print(\"Vectorized train data: \" + str(x_train[0]))\n","print(\"Vectorized test data: \" + str(x_test[0]))\n","\n","y_train = np.asarray(train_labels).astype('float32')\n","y_test = np.asarray(test_labels).astype('float32')\n","print(y_train[0])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeiILpQ9hXdm","colab_type":"code","colab":{}},"source":["#  Here is model starts\n","\n","model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(16, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam',\n","              loss='mse',\n","              metrics=['acc'])\n","\n","#  Separate training and validation data: (WHY? we have test data already)\n","x_val = x_train[:10000]\n","partial_x_train = x_train[10000:]\n","\n","y_val = y_train[:10000]\n","partial_y_train = y_train[10000:]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzNVtBv6heRY","colab_type":"code","colab":{}},"source":["#  train our model\n","history = model.fit(x_train,\n","                    y_train,\n","                    epochs=5,\n","                    batch_size=64,\n","          validation_data=(x_test, y_test))\n","\n","history_dict = history.history  # dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n","print(\"Results: {}\".format(history_dict))\n","\n","#print(\"Predicted 5: {}, 15: {}, 25: {}\".format(model.predict(x_test[5]), model.predict(x_test[15]), model.predict(x_test[25])))\n","\n","#  plotting results\n","loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","acc = history_dict['acc']\n","val_acc_values = history_dict['val_acc']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n","plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()\n","\n","# second plot\n","\n","plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n","plt.plot(epochs, val_acc_values, 'b', label='Validation Accuracy')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]}]}